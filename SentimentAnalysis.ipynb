{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZoK4sf5hu_"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QoKgfLd5hBW"
      },
      "source": [
        "import torch,torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets \n",
        "import random\n",
        "import spacy\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hej7n-yRDL7w"
      },
      "source": [
        "#Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRCnSVlF5QA_"
      },
      "source": [
        "First step is to generate biagram features as described in the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG6-2QVYhaGo"
      },
      "source": [
        "def bigramF(sentence):\n",
        "  '''\n",
        "  l=sentence\n",
        "  unigrams=[]\n",
        "  bigrams= []\n",
        "\n",
        "  for i in range(len(l)):\n",
        "    \n",
        "    unigrams.append( l[i])\n",
        "    if i <len(l)-1:\n",
        "       \n",
        "      bigrams = bigrams +[l[i]+' '+l[i+1]]\n",
        "  return unigrams+bigrams\n",
        "  '''\n",
        "   \n",
        "  for ngram in set(zip(*[sentence[i:]for i in range(2)])):\n",
        "    sentence.append(' '.join (ngram))\n",
        "  return sentence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqyGvOEs5or4"
      },
      "source": [
        "Example of how this looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_jjzAstiyBM",
        "outputId": "9e14dee7-9db9-4fcb-d118-8feedd962194"
      },
      "source": [
        "sentence='this film is great'\n",
        "sent=sentence.split()\n",
        "bigramF(sen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'film', 'is', 'great', 'this film', 'film is', 'is great']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKJebFYS5u71"
      },
      "source": [
        "Setting the random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIgolxUSGt__"
      },
      "source": [
        "def setSeed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "seed=124\n",
        "setSeed(seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn2eDMc_52YV"
      },
      "source": [
        "Then we initialize the torch.text data Field object to build/tokenize & preprocess our texts and labels .Then we use IMDB dataset that is already available on torch.text and build the vocabulary of this data . The output is a dictionary with words indexed and its glove 100d pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy-OSuI9C_Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27b5677-9421-4baf-bd70-fec3f7c4b9db"
      },
      "source": [
        "TEXT=data.Field(tokenize='spacy',tokenizer_language='en_core_web_sm',preprocessing=bigramF)\n",
        "LABEL=data.LabelField(dtype=torch.float)\n",
        "\n",
        "# make splits for data\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
        "# build the vocabulary\n",
        "\n",
        "TEXT.build_vocab(train,unk_init=torch.normal,max_size=25000,vectors='glove.6B.100d')\n",
        "LABEL.build_vocab(train)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 29.3MB/s]\n",
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399981/400000 [00:13<00:00, 29057.85it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irq2bc7m5_vR"
      },
      "source": [
        "We split traindata , and then load the iterator to loop through data in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7r5_Ies9_Ez"
      },
      "source": [
        "traindata ,  valid = train.split(random_state=random.seed(seed))\n",
        "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "trainLoader,validLoader,testLoader=data.BucketIterator.splits(datasets=(traindata,valid,test),batch_size=64,device=device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbKHXybkDPKs"
      },
      "source": [
        "#Build the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9RkfCGk7eJ3"
      },
      "source": [
        "The model is implemented as in the paper , Embedding layer at first and then the output is averaged across the input dimension(which is vocabulary size ) using average pooling filter .Then a linear layer follows to return the final output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efyrZ5w3a_tz"
      },
      "source": [
        "class FastText(nn.Module):\n",
        "  def __init__(self,inputdim,embeddim,hiddim,outputdim,pad_idx):\n",
        "      super().__init__()\n",
        "      self.embedding=nn.Embedding(inputdim,embeddim,padding_idx=pad_idx)\n",
        "      self.linear=nn.Linear(embeddim,outputdim)\n",
        "      \n",
        "  def forward(self,input):\n",
        "    ##print('input ',input.shape)\n",
        "    embed=self.embedding(input)\n",
        "   \n",
        "    embed=embed.permute(1,0,2)\n",
        "    avg=F.avg_pool2d(embed,(embed.shape[1],1)).squeeze(1)\n",
        "    #print('avg ',avg.shape)\n",
        "    output=self.linear(avg)\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEtylV7UDRgI"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYPijnvU-qGM"
      },
      "source": [
        "Defining attributes of the model  and the train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqYTanGDo_Zy"
      },
      "source": [
        "inputdim=len(TEXT.vocab)\n",
        "embeddim=100\n",
        "hiddim=10\n",
        "outputdim=1\n",
        "pad_idx=TEXT.vocab.stoi[TEXT.pad_token]\n",
        "model=FastText(inputdim,embeddim,hiddim,outputdim,pad_idx)\n",
        "model.to(device)\n",
        "optimizor=torch.optim.Adam(model.parameters())\n",
        "criterion=nn.BCEWithLogitsLoss()\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms64lfrzvGoI"
      },
      "source": [
        "def train(loader,model,criterion,optimizor):\n",
        "  model.train()\n",
        "  epoch_loss=0\n",
        "  loss=0\n",
        "  accuracy=0\n",
        "  for batch in loader:\n",
        "    optimizor.zero_grad()\n",
        "\n",
        "    output=model(batch.text)\n",
        "    \n",
        "    loss=criterion(output.squeeze(1),batch.label)\n",
        "    loss.backward()\n",
        "    optimizor.step()\n",
        "    epoch_loss+=loss.item()\n",
        "    accuracy+=acc(output.squeeze(1),batch.label).item()\n",
        " \n",
        "  return epoch_loss/len(loader),accuracy/len(loader)\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkbrkIFy2m2"
      },
      "source": [
        "def evaluate(loader,model,criterion):\n",
        "  model.eval()\n",
        "  epoch_loss,loss=0, 0\n",
        "  accuracy=0\n",
        "  for batch in loader:\n",
        "    with torch.no_grad():\n",
        "   \n",
        "      output=model(batch.text)\n",
        "      loss=criterion(output.squeeze(1),batch.label)\n",
        "      epoch_loss+=loss.item()\n",
        "      accuracy+=acc(output.squeeze(1),batch.label).item()\n",
        "    \n",
        "  return epoch_loss/len(loader) ,accuracy/len(loader)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVTenYKY_4kI"
      },
      "source": [
        "#Binary Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmeuFLcm_-7l"
      },
      "source": [
        "A function to calculate sum of correct predicted classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfGoBs2-_57i"
      },
      "source": [
        "def acc(predicted, groundtruth):\n",
        "  \n",
        "  predicted=torch.sigmoid(predicted)\n",
        "  predicted [predicted>0.5]=1\n",
        "  predicted[predicted<=0.5]=0\n",
        "  \n",
        "  return torch.sum(torch.eq(predicted.detach(),groundtruth))/len(predicted)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3LSa6cTof1a"
      },
      "source": [
        "#Epoch time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPMsXSh8oiD4"
      },
      "source": [
        "import time \n",
        "def epochT(start, end):\n",
        "  min=int((end-start)/60)\n",
        "  sec=int((end-start) - min*60)\n",
        "  return min, sec"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KWBR1Lq-2BX"
      },
      "source": [
        "Running the model for a number of epochs and output the best validation accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TArWA41559Gt",
        "outputId": "53108436-74b3-4fd4-e3fd-f6d6fbf90731"
      },
      "source": [
        "best_loss=float('inf')\n",
        "for epoch in range(5):\n",
        "  start=time.time()\n",
        "  trainloss,train_acc=train(trainLoader,model,criterion,optimizor)\n",
        "  validloss,val_acc=evaluate(validLoader,model,criterion)\n",
        "  end=time.time()\n",
        "  min,sec=epochT(start,end)\n",
        "  print(f'train loss is  :{trainloss:.2f} and train_accuracy is {train_acc:.2f} trained on {min} minutes and {sec} seconds')\n",
        "  print(f'validation loss is {validloss:.2f} and validation_accuracy is {val_acc:.2f} evaluated on {min} minutes and {sec} seconds ')\n",
        "  if validloss<best_loss:\n",
        "    best_loss=validloss\n",
        "    torch.save(model.state_dict(),'SentimentModel.pt')\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss is  :0.61 and train_accuracy is 0.77 trained on 0 minutes and 9 seconds\n",
            "validation loss is 0.47 and validation_accuracy is 0.78 evaluated on 0 minutes and 9 seconds \n",
            "train loss is  :0.54 and train_accuracy is 0.82 trained on 0 minutes and 9 seconds\n",
            "validation loss is 0.42 and validation_accuracy is 0.81 evaluated on 0 minutes and 9 seconds \n",
            "train loss is  :0.48 and train_accuracy is 0.85 trained on 0 minutes and 9 seconds\n",
            "validation loss is 0.39 and validation_accuracy is 0.84 evaluated on 0 minutes and 9 seconds \n",
            "train loss is  :0.43 and train_accuracy is 0.87 trained on 0 minutes and 9 seconds\n",
            "validation loss is 0.38 and validation_accuracy is 0.86 evaluated on 0 minutes and 9 seconds \n",
            "train loss is  :0.38 and train_accuracy is 0.89 trained on 0 minutes and 9 seconds\n",
            "validation loss is 0.39 and validation_accuracy is 0.86 evaluated on 0 minutes and 9 seconds \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IID4Kd_vn3UM"
      },
      "source": [
        "#Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiEmFLu1n5z5",
        "outputId": "c074b1aa-a490-4686-cc91-6085f1fbb12d"
      },
      "source": [
        "model.load_state_dict(torch.load('SentimentModel.pt'))\n",
        "_,accurac=evaluate(testLoader,model,criterion)\n",
        "print(f'Test accuracy is {accurac:.2f} ')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.85 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cri3_d_DbFn"
      },
      "source": [
        "#User input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc3gr7XQ_TCw"
      },
      "source": [
        "classify a user input if positive or negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iNxgacI71gW"
      },
      "source": [
        "lang=spacy.load('en_core_web_sm')\n",
        "def predict(sentence,model):\n",
        "  tokenized=[token.text for token in lang.tokenizer(sentence)]\n",
        "  preprocessed=bigramF(tokenized)\n",
        " \n",
        "  onehot=[TEXT.vocab.stoi[s] for s in preprocessed]\n",
        "  tensor=torch.LongTensor(onehot).to(device)\n",
        "  tensor=tensor.unsqueeze(1)\n",
        " \n",
        "  output=torch.sum(torch.sigmoid(model(tensor)) > 0.5)\n",
        "  return output.item()\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R9SB3Utj_W5n",
        "outputId": "b7639837-a535-4cb9-946a-0b4e907e2a0d"
      },
      "source": [
        "\n",
        "input='this movie really good excellent '\n",
        "model.load_state_dict(torch.load('SentimentModel.pt'))\n",
        "LABEL.vocab.itos[predict(input ,model)]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    }
  ]
}